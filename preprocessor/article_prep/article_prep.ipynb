{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "df1 = pd.read_csv('/Users/stillssi/Desktop/ASSJ/data/news1.csv')\n",
    "df2 = pd.read_csv('/Users/stillssi/Downloads/article_list (1).csv')\n",
    "df = pd.concat([df1,df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['content'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def preprocessing(text, writer=None, press=None):\n",
    "    '''\n",
    "    뉴스기사 전처리 함수입니다.\n",
    "    writer = 기자명\n",
    "    press = 언론사\n",
    "    '''\n",
    "    # 숫자, 소숫점 제거\n",
    "    text = re.sub('\\d+\\.\\d*', '',text)\n",
    "\n",
    "    # 이메일, URl 제거\n",
    "    text = re.sub(\"([a-zA-Z0-9-]+(\\@|\\.)[a-zA-Z0-9-.]+)\", '', text)\n",
    "    text = re.sub(r\"[a-zA-Z0-9]\", '', text)\n",
    "    # 다수의 점 (ex : ...) 점 한개로 대체\n",
    "    text = re.sub(\"\\.+\\.\", '.', text)\n",
    "    # 다수의 공백 축소\n",
    "    parenthesize_pattern = re.compile(r\"\\[[^]]*\\]|\\([^)]*\\)|\\<[^>]*\\>|\\【[^\\】]*\\】|\\＜[^\\＞]*\\＞\")\n",
    "    text = parenthesize_pattern.sub(\"\", text).strip()\n",
    "    reporter_pattern = re.compile(r\"([가-힣]{2,5} 기자)|([가-힣]{2,5}기자)\")\n",
    "    text = reporter_pattern.sub('', text)\n",
    "    symbols = string.punctuation.replace(\".\", \"\").replace(\"?\", \"\").replace(\"!\", \"\") + \"·ㆍ■◆△▷▶▼�\"\"''…※↑↓▲☞ⓒ⅔①②③④⑤⑥⑦⑧⑨⑩○●〈〉‘´´“”?★◇’◇㎡!\"\n",
    "    text = text.translate(str.maketrans(\"\", \"\", symbols))\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = ' '.join(text.split())\n",
    "    # 불용어\n",
    "    if writer:\n",
    "        text = text.replace(writer, '')\n",
    "    if press:\n",
    "        text = text.replace(press, '')\n",
    "\n",
    "    text = text.replace('Copyrights', '').replace('무단 전재 및 재배포 금지', '')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_morphs(data):\n",
    "    pos_list = {'NNG', 'VA', 'VAX', 'MAG', 'NNP', 'VV+EC','VV+ETM'}\n",
    "    mecab = Mecab()\n",
    "    data_token = mecab.morphs(data)\n",
    "    data_token = ' '.join(data_token)\n",
    "    pos_token = mecab.pos(data_token)\n",
    "    pos_result = []\n",
    "    for p in pos_token:\n",
    "        if p[1] in pos_list:\n",
    "            pos_result.append(p[0])\n",
    "    pos_result = list(set(pos_result))\n",
    "    \n",
    "    return ' '.join(pos_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prep'] = ''\n",
    "df['ngram'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(df))):\n",
    "    text = preprocessing(df['content'].iloc[i])\n",
    "    text = ' '.join(text.split('.')[:-1])\n",
    "    text = mecab_morphs(text)\n",
    "    df['prep'].iloc[i] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./ko-dic.txt', 'r')\n",
    "lines = f.readlines()\n",
    "stopwords_list = []\n",
    "for l in lines:\n",
    "    l = l.replace('\\n','')\n",
    "    stopwords_list.append(l)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords_list = list(set(stopwords_list))\n",
    "# w = open('./ko-dic.txt', 'a+')\n",
    "\n",
    "# for i in stopwords_list:\n",
    "#     w.write(i+'\\n')\n",
    "\n",
    "# w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "w = open('./ko-dic.txt', 'a+')\n",
    "mecab = Mecab()\n",
    "for i in tqdm(range(len(df))):\n",
    "    data_token = mecab.morphs(df['prep'].iloc[i]) \n",
    "    result = []\n",
    "    for token in data_token:\n",
    "        if token not in stopwords_list:\n",
    "            result.append(token)\n",
    "    token_result = ' '.join(result)\n",
    "    token_result = token_result.replace('불 확실', '불확실')\n",
    "    token_result = token_result.replace('불 균형', '불균형')\n",
    "    token_result = token_result.replace('불 호황', '불호황')\n",
    "    token_result = token_result.replace('입 주량', '입주량')\n",
    "    \n",
    "    df['ngram'].iloc[i] = token_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['prep', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "# df.rename(columns={'ngram':'prep'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ngram'].iloc[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
